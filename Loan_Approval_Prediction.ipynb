{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAN APPROVAL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\chira\\OneDrive\\Desktop\\SEM 6\\AOML\\AOML_Project_LOAN APPROVAL ANALYZER\\Dataset\\LOAN approval Prediction.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoanAmount\n",
       "120.0    20\n",
       "110.0    17\n",
       "100.0    15\n",
       "160.0    12\n",
       "187.0    12\n",
       "         ..\n",
       "240.0     1\n",
       "214.0     1\n",
       "59.0      1\n",
       "166.0     1\n",
       "253.0     1\n",
       "Name: count, Length: 203, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"LoanAmount\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LoanAmount'].fillna(np.nanmedian(df['LoanAmount']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing categorical values with mode\n",
    "df[\"Gender\"].fillna(df[\"Gender\"].mode()[0], inplace=True)\n",
    "df[\"Married\"].fillna(df[\"Married\"].mode()[0], inplace=True)\n",
    "df[\"Self_Employed\"].fillna(df[\"Self_Employed\"].mode()[0], inplace=True)\n",
    "df[\"Dependents\"].fillna(df[\"Dependents\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Gender', 'Dependents', 'Married', 'Education', 'Self_Employed', 'Credit_History']\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "df['Loan_Status'] = encoder.fit_transform(df['Loan_Status'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for Property_Area\n",
    "dummy_data = pd.get_dummies(df['Property_Area'])\n",
    "df = pd.concat([df, dummy_data], axis=1)\n",
    "df.drop(['Property_Area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debt-to-Income Ratio\n",
    "df[\"Debt_Income_Ratio\"] = df[\"LoanAmount\"] / (df[\"ApplicantIncome\"] + df[\"CoapplicantIncome\"] + 1)\n",
    "\n",
    "# Total Income Feature\n",
    "df[\"Total_Income\"] = df[\"ApplicantIncome\"] + df[\"CoapplicantIncome\"]\n",
    "\n",
    "# Loan to Income Ratio\n",
    "df[\"Loan_Income_Ratio\"] = df[\"LoanAmount\"] / df[\"Total_Income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\", \"Total_Income\"]\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN-TEST SPLIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train : (491, 11)\n",
      "Size of y_train : (491,)\n",
      "Size of X_test : (123, 11)\n",
      "Size of y_test : (123,)\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "\n",
    "X = df.drop(['Loan_Status'], axis=1)\n",
    "y = df['Loan_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\n",
    "\n",
    "print('Size of X_train :', X_train.shape)\n",
    "print('Size of y_train :', y_train.shape)\n",
    "print('Size of X_test :', X_test.shape)\n",
    "print('Size of y_test :', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\2164644233.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['LoanAmount'].fillna(np.nanmedian(df['LoanAmount']), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"loan.csv\")\n",
    "df['LoanAmount'].fillna(np.nanmedian(df['LoanAmount']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Gender', 'Dependents', 'Married', 'Education', 'Self_Employed', 'Credit_History']\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "df['Loan_Status'] = encoder.fit_transform(df['Loan_Status'])\n",
    "\n",
    "# One-hot encoding for Property_Area\n",
    "dummy_data = pd.get_dummies(df['Property_Area'])\n",
    "df = pd.concat([df, dummy_data], axis=1)\n",
    "df.drop(['Property_Area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train : (2000, 13)\n",
      "Size of y_train : (2000,)\n",
      "Size of X_test : (500, 13)\n",
      "Size of y_test : (500,)\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "\n",
    "X = df.drop(['Loan_Status'], axis=1)\n",
    "y = df['Loan_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\n",
    "\n",
    "print('Size of X_train :', X_train.shape)\n",
    "print('Size of y_train :', y_train.shape)\n",
    "print('Size of X_test :', X_test.shape)\n",
    "print('Size of y_test :', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5184 candidates, totalling 25920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:56:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                         &#x27;gamma&#x27;: [0, 0.1, 0.3, 0.5],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500],\n",
       "                         &#x27;reg_lambda&#x27;: [1, 1.5, 2],\n",
       "                         &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.6, 0.8, 1.0],\n",
       "                         &#x27;gamma&#x27;: [0, 0.1, 0.3, 0.5],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 300, 500],\n",
       "                         &#x27;reg_lambda&#x27;: [1, 1.5, 2],\n",
       "                         &#x27;subsample&#x27;: [0.6, 0.8, 1.0]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.6, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='logloss', feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                         'gamma': [0, 0.1, 0.3, 0.5],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7, 10],\n",
       "                         'n_estimators': [100, 300, 500],\n",
       "                         'reg_lambda': [1, 1.5, 2],\n",
       "                         'subsample': [0.6, 0.8, 1.0]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_xgb_model = grid_search.best_estimator_\n",
    "tuned_xgb_preds = tuned_xgb_model.predict(X_test)\n",
    "tuned_xgb_f1 = f1_score(y_test, tuned_xgb_preds)\n",
    "tuned_xgb_acc = accuracy_score(y_test, tuned_xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost - F1 Score: 1.0, Accuracy: 1.0\n",
      "Best Parameters: {'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 500, 'reg_lambda': 2, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Save the best-tuned model\n",
    "joblib.dump(tuned_xgb_model, \"best_xgb_loan_model.h5\")\n",
    "\n",
    "# Print model performance\n",
    "print(f\"Best XGBoost - F1 Score: {tuned_xgb_f1}, Accuracy: {tuned_xgb_acc}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\3285942381.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"loan.csv\")\n",
    "df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Gender', 'Dependents', 'Married', 'Education', 'Self_Employed', 'Credit_History']\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "df['Loan_Status'] = encoder.fit_transform(df['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.get_dummies(df['Property_Area'])\n",
    "df = pd.concat([df, dummy_data], axis=1)\n",
    "df.drop(['Property_Area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Loan_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train : (2000, 13)\n",
      "Size of y_train : (2000,)\n",
      "Size of X_test : (500, 13)\n",
      "Size of y_test : (500,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Loan_Status'], axis=1)\n",
    "y = df['Loan_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\n",
    "\n",
    "print('Size of X_train :', X_train.shape)\n",
    "print('Size of y_train :', y_train.shape)\n",
    "print('Size of X_test :', X_test.shape)\n",
    "print('Size of y_test :', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'iterations': [100, 300, 500],\n",
    "    'depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7],\n",
    "    'border_count': [32, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;catboost.core.CatBoostClassifier object at 0x0000023AE7D70460&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;border_count&#x27;: [32, 50, 100], &#x27;depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;iterations&#x27;: [100, 300, 500],\n",
       "                         &#x27;l2_leaf_reg&#x27;: [1, 3, 5, 7],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;catboost.core.CatBoostClassifier object at 0x0000023AE7D70460&gt;,\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;border_count&#x27;: [32, 50, 100], &#x27;depth&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;iterations&#x27;: [100, 300, 500],\n",
       "                         &#x27;l2_leaf_reg&#x27;: [1, 3, 5, 7],\n",
       "                         &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2]},\n",
       "             scoring=&#x27;f1&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: CatBoostClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000023AEA5DAD40&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CatBoostClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x0000023AEA5DAD40&gt;</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x0000023AE7D70460>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'border_count': [32, 50, 100], 'depth': [3, 5, 7, 10],\n",
       "                         'iterations': [100, 300, 500],\n",
       "                         'l2_leaf_reg': [1, 3, 5, 7],\n",
       "                         'learning_rate': [0.01, 0.05, 0.1, 0.2]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost = CatBoostClassifier(verbose=0)\n",
    "grid_search = GridSearchCV(catboost, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_catboost_model = grid_search.best_estimator_\n",
    "tuned_catboost_preds = tuned_catboost_model.predict(X_test)\n",
    "tuned_catboost_f1 = f1_score(y_test, tuned_catboost_preds)\n",
    "tuned_catboost_acc = accuracy_score(y_test, tuned_catboost_preds)\n",
    "tuned_catboost_precision = precision_score(y_test, tuned_catboost_preds)\n",
    "tuned_catboost_recall = recall_score(y_test, tuned_catboost_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost - F1 Score: 0.998766954377312, Accuracy: 0.998, Precision: 0.9975369458128078, Recall: 1.0\n",
      "Best Parameters: {'border_count': 100, 'depth': 3, 'iterations': 100, 'l2_leaf_reg': 3, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Save the best-tuned model using pickle\n",
    "filename = 'CatBoost_Classifier.model'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(tuned_catboost_model, file)\n",
    "\n",
    "# Print model performance\n",
    "print(f\"Best CatBoost - F1 Score: {tuned_catboost_f1}, Accuracy: {tuned_catboost_acc}, Precision: {tuned_catboost_precision}, Recall: {tuned_catboost_recall}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"loan.csv\")\n",
    "\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical variables\n",
    "categorical_cols = ['Gender', 'Dependents', 'Married', 'Education', 'Self_Employed', 'Credit_History']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "df['Loan_Status'] = df['Loan_Status'].astype('category').cat.codes\n",
    "\n",
    "# One-hot encoding for Property_Area\n",
    "dummy_data = pd.get_dummies(df['Property_Area'])\n",
    "df = pd.concat([df, dummy_data], axis=1)\n",
    "df.drop(['Property_Area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "\n",
    "selected_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Gender', 'Married', 'Education', 'Self_Employed', 'Dependents', 'Semiurban', 'Urban', 'Rural']\n",
    "X = df[selected_features]\n",
    "y = df['Loan_Status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train : (2000, 13)\n",
      "Size of y_train : (2000,)\n",
      "Size of X_test : (500, 13)\n",
      "Size of y_test : (500,)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\n",
    "\n",
    "# Print dataset sizes\n",
    "print('Size of X_train :', X_train.shape)\n",
    "print('Size of y_train :', y_train.shape)\n",
    "print('Size of X_test :', X_test.shape)\n",
    "print('Size of y_test :', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(knn_classifier, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best KNN model\n",
    "tuned_knn_model = grid_search_knn.best_estimator_\n",
    "tuned_knn_preds = tuned_knn_model.predict(X_test)\n",
    "tuned_knn_f1 = f1_score(y_test, tuned_knn_preds)\n",
    "tuned_knn_acc = accuracy_score(y_test, tuned_knn_preds)\n",
    "tuned_knn_precision = precision_score(y_test, tuned_knn_preds)\n",
    "tuned_knn_recall = recall_score(y_test, tuned_knn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized KNN Classifier - F1 Score: 0.9794437726723095, Accuracy: 0.966, Precision: 0.9619952494061758, Recall: 0.9975369458128078\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Optimized KNN Classifier - F1 Score: {tuned_knn_f1}, Accuracy: {tuned_knn_acc}, Precision: {tuned_knn_precision}, Recall: {tuned_knn_recall}')\n",
    "print(f'Best Parameters: {grid_search_knn.best_params_}')\n",
    "\n",
    "# Saving Optimized KNN Model Using Pickle\n",
    "filename_knn = 'KNN_Classifier_Optimized2.model'\n",
    "with open(filename_knn, 'wb') as file:\n",
    "    pickle.dump(tuned_knn_model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"loan.csv\")\n",
    "\n",
    "# Handling missing values\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Encoding categorical variables\n",
    "categorical_cols = ['Gender', 'Dependents', 'Married', 'Education', 'Self_Employed', 'Credit_History']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "df['Loan_Status'] = df['Loan_Status'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for Property_Area\n",
    "dummy_data = pd.get_dummies(df['Property_Area'])\n",
    "df = pd.concat([df, dummy_data], axis=1)\n",
    "df.drop(['Property_Area'], axis=1, inplace=True)\n",
    "\n",
    "# Drop Loan_ID column\n",
    "df.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "\n",
    "# Selecting 13 features for consistency\n",
    "selected_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Gender', 'Married', 'Education', 'Self_Employed', 'Dependents', 'Semiurban', 'Urban', 'Rural']\n",
    "X = df[selected_features]\n",
    "y = df['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train : (2000, 13)\n",
      "Size of y_train : (2000,)\n",
      "Size of X_test : (500, 13)\n",
      "Size of y_test : (500,)\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=300)\n",
    "\n",
    "# Print dataset sizes\n",
    "print('Size of X_train :', X_train.shape)\n",
    "print('Size of y_train :', y_train.shape)\n",
    "print('Size of X_test :', X_test.shape)\n",
    "print('Size of y_test :', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=300)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_preds = rf_classifier.predict(X_test)\n",
    "rf_f1 = f1_score(y_test, rf_preds)\n",
    "rf_acc = accuracy_score(y_test, rf_preds)\n",
    "rf_precision = precision_score(y_test, rf_preds)\n",
    "rf_recall = recall_score(y_test, rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier - F1 Score: 1.0, Accuracy: 1.0, Precision: 1.0, Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest Classifier - F1 Score: {rf_f1}, Accuracy: {rf_acc}, Precision: {rf_precision}, Recall: {rf_recall}')\n",
    "\n",
    "# Saving Random Forest Model Using Pickle\n",
    "filename_rf = 'RandomForest_Classifier.model'\n",
    "with open(filename_rf, 'wb') as file:\n",
    "    pickle.dump(rf_classifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths_f1_score = []\n",
    "depths_test_f1_score = []\n",
    "depths_test_acc_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "d_val = []\n",
    "for d in range(1,30):\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=300, max_depth=d)\n",
    "    dt_classifier.fit(X_train, y_train)\n",
    "    dt_f1_score = np.mean(cross_val_score(dt_classifier, X_train, y_train, scoring='f1', cv=5))\n",
    "    depths_f1_score.append(dt_f1_score)\n",
    "    d_val.append(d)\n",
    "    \n",
    "    predictions = dt_classifier.predict(X_test)\n",
    "    # Caculating F1 Score\n",
    "    dt_test_f1_score = f1_score(y_test, predictions)\n",
    "    dt_test_acc_score = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    depths_test_f1_score.append(dt_test_f1_score)\n",
    "    depths_test_acc_score.append(dt_test_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(random_state=300, max_depth=4)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "dt_f1_score = np.mean(cross_val_score(dt_classifier, X_train, y_train, scoring='f1', cv=5))\n",
    "\n",
    "predictions = dt_classifier.predict(X_test)\n",
    "# Caculating F1 Score\n",
    "dt_test_f1_score = f1_score(y_test, predictions)\n",
    "dt_test_acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(15,10))\n",
    "plot_tree(dt_classifier)\n",
    "plt.title('Decision Tree For Prediction Of Customer Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Decision Tree Model Using Pickle\n",
    "import pickle\n",
    "filename = 'Decison_Tree_Classifier.model'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(dt_classifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHTGBM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 22:11:36,289] A new study created in memory with name: no-name-15023fdb-60ed-42bb-ba38-a8f25b4bf12c\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,481] Trial 0 finished with value: 0.0 and parameters: {'num_leaves': 128, 'min_data_in_leaf': 34, 'feature_fraction': 0.4043562430730604, 'bagging_fraction': 0.7590876667816107, 'bagging_freq': 3, 'lambda_l1': 0.13378326428511275, 'lambda_l2': 2.973908766069235e-05, 'learning_rate': 0.13866478254631442, 'max_depth': 4}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,515] Trial 1 finished with value: 0.0 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 38, 'feature_fraction': 0.9426873598854901, 'bagging_fraction': 0.8805871296432797, 'bagging_freq': 7, 'lambda_l1': 0.04377872104806144, 'lambda_l2': 1.0534072899061082, 'learning_rate': 0.12231755323076894, 'max_depth': 3}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,564] Trial 2 finished with value: 0.0 and parameters: {'num_leaves': 80, 'min_data_in_leaf': 61, 'feature_fraction': 0.7736182430355968, 'bagging_fraction': 0.8028785330207946, 'bagging_freq': 6, 'lambda_l1': 1.5817898240866663e-08, 'lambda_l2': 1.8520313832148607e-08, 'learning_rate': 0.16441751200490792, 'max_depth': 10}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,607] Trial 3 finished with value: 0.0 and parameters: {'num_leaves': 128, 'min_data_in_leaf': 71, 'feature_fraction': 0.7671729562788417, 'bagging_fraction': 0.8262376254300591, 'bagging_freq': 1, 'lambda_l1': 4.947637624511137e-06, 'lambda_l2': 8.685236982082514e-05, 'learning_rate': 0.2858815855861289, 'max_depth': 8}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4043562430730604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4043562430730604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13378326428511275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13378326428511275\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.973908766069235e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.973908766069235e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7590876667816107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7590876667816107\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4043562430730604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4043562430730604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13378326428511275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13378326428511275\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.973908766069235e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.973908766069235e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7590876667816107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7590876667816107\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4043562430730604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4043562430730604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13378326428511275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13378326428511275\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.973908766069235e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.973908766069235e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7590876667816107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7590876667816107\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4043562430730604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4043562430730604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13378326428511275, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13378326428511275\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.973908766069235e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.973908766069235e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7590876667816107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7590876667816107\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426873598854901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426873598854901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04377872104806144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04377872104806144\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0534072899061082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0534072899061082\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8805871296432797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8805871296432797\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426873598854901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426873598854901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04377872104806144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04377872104806144\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0534072899061082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0534072899061082\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8805871296432797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8805871296432797\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426873598854901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426873598854901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04377872104806144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04377872104806144\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0534072899061082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0534072899061082\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8805871296432797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8805871296432797\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9426873598854901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9426873598854901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04377872104806144, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04377872104806144\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0534072899061082, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0534072899061082\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8805871296432797, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8805871296432797\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7736182430355968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7736182430355968\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5817898240866663e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5817898240866663e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8520313832148607e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8520313832148607e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8028785330207946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8028785330207946\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7736182430355968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7736182430355968\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5817898240866663e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5817898240866663e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8520313832148607e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8520313832148607e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8028785330207946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8028785330207946\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7736182430355968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7736182430355968\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5817898240866663e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5817898240866663e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8520313832148607e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8520313832148607e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8028785330207946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8028785330207946\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7736182430355968, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7736182430355968\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5817898240866663e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5817898240866663e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.8520313832148607e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.8520313832148607e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8028785330207946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8028785330207946\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7671729562788417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7671729562788417\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.947637624511137e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.947637624511137e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.685236982082514e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.685236982082514e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8262376254300591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8262376254300591\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7671729562788417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7671729562788417\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.947637624511137e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.947637624511137e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.685236982082514e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.685236982082514e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8262376254300591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8262376254300591\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7671729562788417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7671729562788417\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.947637624511137e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.947637624511137e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.685236982082514e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.685236982082514e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8262376254300591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8262376254300591\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7671729562788417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7671729562788417\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.947637624511137e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.947637624511137e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.685236982082514e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.685236982082514e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8262376254300591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8262376254300591\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,663] Trial 4 finished with value: 0.0 and parameters: {'num_leaves': 167, 'min_data_in_leaf': 21, 'feature_fraction': 0.9784137439356824, 'bagging_fraction': 0.731037055377662, 'bagging_freq': 1, 'lambda_l1': 2.3415457671258935e-05, 'lambda_l2': 2.1313897279161623e-07, 'learning_rate': 0.04276762606866128, 'max_depth': 10}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,722] Trial 5 finished with value: 0.0 and parameters: {'num_leaves': 31, 'min_data_in_leaf': 34, 'feature_fraction': 0.5010097044315425, 'bagging_fraction': 0.6057790808060751, 'bagging_freq': 3, 'lambda_l1': 0.009773367538414564, 'lambda_l2': 0.013666634686116319, 'learning_rate': 0.05756045866816273, 'max_depth': 6}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,791] Trial 6 finished with value: 0.0 and parameters: {'num_leaves': 91, 'min_data_in_leaf': 31, 'feature_fraction': 0.7293896337392629, 'bagging_fraction': 0.695023435410973, 'bagging_freq': 1, 'lambda_l1': 0.015672850664614827, 'lambda_l2': 2.0660243956654027e-06, 'learning_rate': 0.0604917418856272, 'max_depth': 14}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9784137439356824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9784137439356824\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3415457671258935e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3415457671258935e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1313897279161623e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1313897279161623e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731037055377662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731037055377662\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9784137439356824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9784137439356824\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3415457671258935e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3415457671258935e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1313897279161623e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1313897279161623e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731037055377662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731037055377662\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9784137439356824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9784137439356824\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3415457671258935e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3415457671258935e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1313897279161623e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1313897279161623e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731037055377662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731037055377662\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9784137439356824, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9784137439356824\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.3415457671258935e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3415457671258935e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1313897279161623e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1313897279161623e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.731037055377662, subsample=1.0 will be ignored. Current value: bagging_fraction=0.731037055377662\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5010097044315425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5010097044315425\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009773367538414564, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009773367538414564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.013666634686116319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013666634686116319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6057790808060751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6057790808060751\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5010097044315425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5010097044315425\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009773367538414564, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009773367538414564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.013666634686116319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013666634686116319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6057790808060751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6057790808060751\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5010097044315425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5010097044315425\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009773367538414564, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009773367538414564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.013666634686116319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013666634686116319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6057790808060751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6057790808060751\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5010097044315425, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5010097044315425\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009773367538414564, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009773367538414564\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.013666634686116319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013666634686116319\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6057790808060751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6057790808060751\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7293896337392629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7293896337392629\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015672850664614827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015672850664614827\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0660243956654027e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0660243956654027e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695023435410973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695023435410973\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7293896337392629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7293896337392629\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015672850664614827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015672850664614827\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0660243956654027e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0660243956654027e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695023435410973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695023435410973\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7293896337392629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7293896337392629\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015672850664614827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015672850664614827\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0660243956654027e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0660243956654027e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695023435410973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695023435410973\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7293896337392629, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7293896337392629\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015672850664614827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015672850664614827\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0660243956654027e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0660243956654027e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.695023435410973, subsample=1.0 will be ignored. Current value: bagging_fraction=0.695023435410973\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7975043386701455, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7975043386701455\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.177821078649708e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.177821078649708e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002860377514969696, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002860377514969696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5077657089052311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5077657089052311\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7975043386701455, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7975043386701455\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.177821078649708e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.177821078649708e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002860377514969696, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002860377514969696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5077657089052311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5077657089052311\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7975043386701455, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7975043386701455\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.177821078649708e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.177821078649708e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002860377514969696, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002860377514969696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5077657089052311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5077657089052311\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,853] Trial 7 finished with value: 0.0 and parameters: {'num_leaves': 46, 'min_data_in_leaf': 24, 'feature_fraction': 0.7975043386701455, 'bagging_fraction': 0.5077657089052311, 'bagging_freq': 4, 'lambda_l1': 6.177821078649708e-08, 'lambda_l2': 0.002860377514969696, 'learning_rate': 0.013694541330896315, 'max_depth': 3}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:36,989] Trial 8 finished with value: 0.0 and parameters: {'num_leaves': 173, 'min_data_in_leaf': 92, 'feature_fraction': 0.5200415343265696, 'bagging_fraction': 0.8734908370332839, 'bagging_freq': 4, 'lambda_l1': 4.0702753406810894e-05, 'lambda_l2': 4.2343108181000485e-06, 'learning_rate': 0.0930716916727796, 'max_depth': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7975043386701455, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7975043386701455\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.177821078649708e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.177821078649708e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.002860377514969696, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002860377514969696\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5077657089052311, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5077657089052311\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5200415343265696, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5200415343265696\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0702753406810894e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0702753406810894e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2343108181000485e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2343108181000485e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734908370332839, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734908370332839\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5200415343265696, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5200415343265696\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0702753406810894e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0702753406810894e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2343108181000485e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2343108181000485e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734908370332839, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734908370332839\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5200415343265696, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5200415343265696\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0702753406810894e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0702753406810894e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2343108181000485e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2343108181000485e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734908370332839, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734908370332839\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=92, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=92\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5200415343265696, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5200415343265696\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0702753406810894e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0702753406810894e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2343108181000485e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2343108181000485e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8734908370332839, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8734908370332839\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7019030920105948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7019030920105948\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1201803809278575e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1201803809278575e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9075933009472714e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.9075933009472714e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5166928526010712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5166928526010712\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7019030920105948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7019030920105948\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1201803809278575e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1201803809278575e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9075933009472714e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.9075933009472714e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5166928526010712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5166928526010712\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7019030920105948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7019030920105948\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1201803809278575e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1201803809278575e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9075933009472714e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.9075933009472714e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5166928526010712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5166928526010712\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:37,053] Trial 9 finished with value: 0.0 and parameters: {'num_leaves': 41, 'min_data_in_leaf': 61, 'feature_fraction': 0.7019030920105948, 'bagging_fraction': 0.5166928526010712, 'bagging_freq': 1, 'lambda_l1': 1.1201803809278575e-06, 'lambda_l2': 5.9075933009472714e-08, 'learning_rate': 0.10785620028789175, 'max_depth': 6}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:37,199] Trial 10 finished with value: 0.0 and parameters: {'num_leaves': 132, 'min_data_in_leaf': 11, 'feature_fraction': 0.420050122895743, 'bagging_fraction': 0.9622541691326145, 'bagging_freq': 3, 'lambda_l1': 3.6137088373829425, 'lambda_l2': 3.3536338788513747, 'learning_rate': 0.022866502754070903, 'max_depth': 15}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7019030920105948, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7019030920105948\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1201803809278575e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1201803809278575e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.9075933009472714e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.9075933009472714e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5166928526010712, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5166928526010712\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.420050122895743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.420050122895743\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6137088373829425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6137088373829425\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3536338788513747, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3536338788513747\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9622541691326145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9622541691326145\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.420050122895743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.420050122895743\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6137088373829425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6137088373829425\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3536338788513747, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3536338788513747\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9622541691326145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9622541691326145\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.420050122895743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.420050122895743\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6137088373829425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6137088373829425\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3536338788513747, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3536338788513747\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9622541691326145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9622541691326145\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.420050122895743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.420050122895743\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6137088373829425, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6137088373829425\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3536338788513747, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3536338788513747\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9622541691326145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9622541691326145\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:37,306] Trial 11 finished with value: 0.0 and parameters: {'num_leaves': 200, 'min_data_in_leaf': 45, 'feature_fraction': 0.985323612664102, 'bagging_fraction': 0.964594955189533, 'bagging_freq': 7, 'lambda_l1': 1.3456854451219655, 'lambda_l2': 6.658086247864984, 'learning_rate': 0.21090600646277938, 'max_depth': 3}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:37,410] Trial 12 finished with value: 0.0 and parameters: {'num_leaves': 155, 'min_data_in_leaf': 45, 'feature_fraction': 0.9039653743834367, 'bagging_fraction': 0.6998037603392899, 'bagging_freq': 6, 'lambda_l1': 0.033277135993361684, 'lambda_l2': 0.06347340039323009, 'learning_rate': 0.11594588641942506, 'max_depth': 5}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.985323612664102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.985323612664102\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3456854451219655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3456854451219655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.658086247864984, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.658086247864984\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.964594955189533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.964594955189533\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.985323612664102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.985323612664102\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3456854451219655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3456854451219655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.658086247864984, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.658086247864984\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.964594955189533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.964594955189533\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.985323612664102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.985323612664102\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3456854451219655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3456854451219655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.658086247864984, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.658086247864984\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.964594955189533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.964594955189533\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.985323612664102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.985323612664102\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3456854451219655, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3456854451219655\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.658086247864984, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.658086247864984\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.964594955189533, subsample=1.0 will be ignored. Current value: bagging_fraction=0.964594955189533\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9039653743834367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9039653743834367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033277135993361684, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033277135993361684\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.06347340039323009, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06347340039323009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6998037603392899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6998037603392899\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9039653743834367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9039653743834367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033277135993361684, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033277135993361684\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.06347340039323009, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06347340039323009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6998037603392899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6998037603392899\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9039653743834367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9039653743834367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033277135993361684, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033277135993361684\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.06347340039323009, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06347340039323009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6998037603392899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6998037603392899\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9039653743834367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9039653743834367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033277135993361684, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033277135993361684\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.06347340039323009, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06347340039323009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6998037603392899, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6998037603392899\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:37,525] Trial 13 finished with value: 0.0 and parameters: {'num_leaves': 200, 'min_data_in_leaf': 45, 'feature_fraction': 0.6157548564752806, 'bagging_fraction': 0.8875950633173783, 'bagging_freq': 5, 'lambda_l1': 0.00105962970257263, 'lambda_l2': 0.00022228049791945845, 'learning_rate': 0.1752182176199862, 'max_depth': 4}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:37,640] Trial 14 finished with value: 0.0 and parameters: {'num_leaves': 115, 'min_data_in_leaf': 83, 'feature_fraction': 0.864302660006055, 'bagging_fraction': 0.7712061660327123, 'bagging_freq': 3, 'lambda_l1': 0.25971947613631485, 'lambda_l2': 0.4043305344698224, 'learning_rate': 0.036023842106166354, 'max_depth': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6157548564752806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6157548564752806\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00105962970257263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00105962970257263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00022228049791945845, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00022228049791945845\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8875950633173783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8875950633173783\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6157548564752806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6157548564752806\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00105962970257263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00105962970257263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00022228049791945845, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00022228049791945845\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8875950633173783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8875950633173783\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6157548564752806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6157548564752806\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00105962970257263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00105962970257263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00022228049791945845, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00022228049791945845\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8875950633173783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8875950633173783\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=45, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6157548564752806, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6157548564752806\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00105962970257263, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00105962970257263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00022228049791945845, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00022228049791945845\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8875950633173783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8875950633173783\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=83, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=83\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864302660006055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864302660006055\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25971947613631485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25971947613631485\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4043305344698224, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4043305344698224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712061660327123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712061660327123\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=83, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=83\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864302660006055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864302660006055\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25971947613631485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25971947613631485\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4043305344698224, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4043305344698224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712061660327123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712061660327123\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=83, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=83\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864302660006055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864302660006055\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25971947613631485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25971947613631485\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4043305344698224, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4043305344698224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712061660327123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712061660327123\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=83, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=83\n",
      "[LightGBM] [Warning] feature_fraction is set=0.864302660006055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.864302660006055\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.25971947613631485, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25971947613631485\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4043305344698224, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4043305344698224\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7712061660327123, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7712061660327123\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:37,756] Trial 15 finished with value: 0.0 and parameters: {'num_leaves': 145, 'min_data_in_leaf': 37, 'feature_fraction': 0.5891456245443998, 'bagging_fraction': 0.6188914920004754, 'bagging_freq': 7, 'lambda_l1': 0.0008684262520718499, 'lambda_l2': 2.5452079762388883e-05, 'learning_rate': 0.09238919635687073, 'max_depth': 3}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5891456245443998, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5891456245443998\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008684262520718499, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008684262520718499\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5452079762388883e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5452079762388883e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6188914920004754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6188914920004754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5891456245443998, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5891456245443998\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008684262520718499, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008684262520718499\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5452079762388883e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5452079762388883e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6188914920004754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6188914920004754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5891456245443998, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5891456245443998\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008684262520718499, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008684262520718499\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5452079762388883e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5452079762388883e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6188914920004754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6188914920004754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=37, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=37\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5891456245443998, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5891456245443998\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008684262520718499, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008684262520718499\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5452079762388883e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5452079762388883e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6188914920004754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6188914920004754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6306179112566763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6306179112566763\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12840761493486116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12840761493486116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.000953408026100217, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000953408026100217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8885701480535773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8885701480535773\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6306179112566763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6306179112566763\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12840761493486116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12840761493486116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.000953408026100217, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000953408026100217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8885701480535773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8885701480535773\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6306179112566763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6306179112566763\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12840761493486116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12840761493486116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.000953408026100217, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000953408026100217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8885701480535773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8885701480535773\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6306179112566763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6306179112566763\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.12840761493486116, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.12840761493486116\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.000953408026100217, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.000953408026100217\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8885701480535773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8885701480535773\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 22:11:37,907] Trial 16 finished with value: 0.0 and parameters: {'num_leaves': 88, 'min_data_in_leaf': 13, 'feature_fraction': 0.6306179112566763, 'bagging_fraction': 0.8885701480535773, 'bagging_freq': 2, 'lambda_l1': 0.12840761493486116, 'lambda_l2': 0.000953408026100217, 'learning_rate': 0.27622961107225125, 'max_depth': 12}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,015] Trial 17 finished with value: 0.0 and parameters: {'num_leaves': 171, 'min_data_in_leaf': 53, 'feature_fraction': 0.41292052109236366, 'bagging_fraction': 0.43452666220876573, 'bagging_freq': 5, 'lambda_l1': 4.973735767246832, 'lambda_l2': 0.13803915156571778, 'learning_rate': 0.1381577031628078, 'max_depth': 5}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,116] Trial 18 finished with value: 0.0 and parameters: {'num_leaves': 64, 'min_data_in_leaf': 23, 'feature_fraction': 0.8717039310741044, 'bagging_fraction': 0.9987001783679312, 'bagging_freq': 5, 'lambda_l1': 0.002559533439705802, 'lambda_l2': 5.368700121367373e-06, 'learning_rate': 0.0721973076392162, 'max_depth': 8}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41292052109236366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41292052109236366\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.973735767246832, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.973735767246832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13803915156571778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13803915156571778\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43452666220876573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43452666220876573\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41292052109236366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41292052109236366\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.973735767246832, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.973735767246832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13803915156571778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13803915156571778\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43452666220876573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43452666220876573\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41292052109236366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41292052109236366\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.973735767246832, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.973735767246832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13803915156571778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13803915156571778\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43452666220876573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43452666220876573\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.41292052109236366, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41292052109236366\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.973735767246832, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.973735767246832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13803915156571778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13803915156571778\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43452666220876573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.43452666220876573\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8717039310741044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8717039310741044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002559533439705802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002559533439705802\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.368700121367373e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.368700121367373e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987001783679312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9987001783679312\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8717039310741044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8717039310741044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002559533439705802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002559533439705802\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.368700121367373e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.368700121367373e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987001783679312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9987001783679312\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8717039310741044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8717039310741044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002559533439705802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002559533439705802\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.368700121367373e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.368700121367373e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987001783679312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9987001783679312\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8717039310741044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8717039310741044\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002559533439705802, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002559533439705802\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.368700121367373e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.368700121367373e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9987001783679312, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9987001783679312\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,230] Trial 19 finished with value: 0.0 and parameters: {'num_leaves': 113, 'min_data_in_leaf': 53, 'feature_fraction': 0.49488330111498025, 'bagging_fraction': 0.6260132240494167, 'bagging_freq': 2, 'lambda_l1': 0.3715829161827218, 'lambda_l2': 0.009327396003985841, 'learning_rate': 0.029388772212659293, 'max_depth': 5}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,322] Trial 20 finished with value: 0.0 and parameters: {'num_leaves': 188, 'min_data_in_leaf': 71, 'feature_fraction': 0.6549878500781463, 'bagging_fraction': 0.8194486515067051, 'bagging_freq': 6, 'lambda_l1': 0.00033286562302526994, 'lambda_l2': 4.233227089243448e-07, 'learning_rate': 0.20588822297287807, 'max_depth': 4}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49488330111498025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49488330111498025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3715829161827218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3715829161827218\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.009327396003985841, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009327396003985841\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6260132240494167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6260132240494167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49488330111498025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49488330111498025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3715829161827218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3715829161827218\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.009327396003985841, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009327396003985841\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6260132240494167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6260132240494167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49488330111498025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49488330111498025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3715829161827218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3715829161827218\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.009327396003985841, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009327396003985841\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6260132240494167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6260132240494167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[68]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=53, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=53\n",
      "[LightGBM] [Warning] feature_fraction is set=0.49488330111498025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49488330111498025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3715829161827218, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3715829161827218\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.009327396003985841, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009327396003985841\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6260132240494167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6260132240494167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6549878500781463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6549878500781463\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00033286562302526994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00033286562302526994\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.233227089243448e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.233227089243448e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8194486515067051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8194486515067051\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6549878500781463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6549878500781463\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00033286562302526994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00033286562302526994\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.233227089243448e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.233227089243448e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8194486515067051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8194486515067051\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6549878500781463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6549878500781463\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00033286562302526994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00033286562302526994\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.233227089243448e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.233227089243448e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8194486515067051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8194486515067051\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=71, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=71\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6549878500781463, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6549878500781463\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00033286562302526994, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00033286562302526994\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.233227089243448e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.233227089243448e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8194486515067051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8194486515067051\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,420] Trial 21 finished with value: 0.0 and parameters: {'num_leaves': 94, 'min_data_in_leaf': 61, 'feature_fraction': 0.8403434615584553, 'bagging_fraction': 0.8091312542203833, 'bagging_freq': 6, 'lambda_l1': 4.713651803815231e-08, 'lambda_l2': 4.179677409581139e-08, 'learning_rate': 0.1759620255818866, 'max_depth': 12}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,540] Trial 22 finished with value: 0.0 and parameters: {'num_leaves': 70, 'min_data_in_leaf': 40, 'feature_fraction': 0.9464563083166881, 'bagging_fraction': 0.7643479090249634, 'bagging_freq': 7, 'lambda_l1': 2.420728486491664e-07, 'lambda_l2': 2.3293852613309004e-05, 'learning_rate': 0.15198473202498636, 'max_depth': 11}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8403434615584553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8403434615584553\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.713651803815231e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.713651803815231e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.179677409581139e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.179677409581139e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8091312542203833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8091312542203833\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8403434615584553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8403434615584553\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.713651803815231e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.713651803815231e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.179677409581139e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.179677409581139e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8091312542203833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8091312542203833\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8403434615584553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8403434615584553\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.713651803815231e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.713651803815231e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.179677409581139e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.179677409581139e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8091312542203833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8091312542203833\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8403434615584553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8403434615584553\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.713651803815231e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.713651803815231e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.179677409581139e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.179677409581139e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8091312542203833, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8091312542203833\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9464563083166881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9464563083166881\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.420728486491664e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.420728486491664e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3293852613309004e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3293852613309004e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643479090249634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643479090249634\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9464563083166881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9464563083166881\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.420728486491664e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.420728486491664e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3293852613309004e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3293852613309004e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643479090249634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643479090249634\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9464563083166881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9464563083166881\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.420728486491664e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.420728486491664e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3293852613309004e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3293852613309004e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643479090249634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643479090249634\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9464563083166881, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9464563083166881\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.420728486491664e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.420728486491664e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.3293852613309004e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3293852613309004e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7643479090249634, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7643479090249634\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,639] Trial 23 finished with value: 0.0 and parameters: {'num_leaves': 76, 'min_data_in_leaf': 74, 'feature_fraction': 0.8050781420477103, 'bagging_fraction': 0.9144138256286332, 'bagging_freq': 6, 'lambda_l1': 4.423847125841481e-05, 'lambda_l2': 1.1053866363673574e-08, 'learning_rate': 0.08762794739273368, 'max_depth': 9}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,721] Trial 24 finished with value: 0.0 and parameters: {'num_leaves': 139, 'min_data_in_leaf': 62, 'feature_fraction': 0.9227851343453553, 'bagging_fraction': 0.8419833714618048, 'bagging_freq': 7, 'lambda_l1': 0.05073433860135579, 'lambda_l2': 0.8894674728054586, 'learning_rate': 0.1282860071387283, 'max_depth': 7}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8050781420477103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8050781420477103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.423847125841481e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.423847125841481e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1053866363673574e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1053866363673574e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9144138256286332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9144138256286332\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8050781420477103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8050781420477103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.423847125841481e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.423847125841481e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1053866363673574e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1053866363673574e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9144138256286332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9144138256286332\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8050781420477103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8050781420477103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.423847125841481e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.423847125841481e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1053866363673574e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1053866363673574e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9144138256286332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9144138256286332\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=74, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=74\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8050781420477103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8050781420477103\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.423847125841481e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.423847125841481e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1053866363673574e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1053866363673574e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9144138256286332, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9144138256286332\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227851343453553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227851343453553\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05073433860135579, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05073433860135579\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8894674728054586, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8894674728054586\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419833714618048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419833714618048\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227851343453553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227851343453553\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05073433860135579, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05073433860135579\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8894674728054586, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8894674728054586\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419833714618048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419833714618048\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227851343453553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227851343453553\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05073433860135579, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05073433860135579\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8894674728054586, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8894674728054586\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419833714618048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419833714618048\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=62, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=62\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9227851343453553, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9227851343453553\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05073433860135579, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05073433860135579\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8894674728054586, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8894674728054586\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8419833714618048, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8419833714618048\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,864] Trial 25 finished with value: 0.0 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 28, 'feature_fraction': 0.5727527857427196, 'bagging_fraction': 0.7713845502468794, 'bagging_freq': 5, 'lambda_l1': 1.2073366088785194e-08, 'lambda_l2': 6.586558226753304e-07, 'learning_rate': 0.06899640428416728, 'max_depth': 13}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:38,954] Trial 26 finished with value: 0.0 and parameters: {'num_leaves': 153, 'min_data_in_leaf': 50, 'feature_fraction': 0.7398806064642335, 'bagging_fraction': 0.6609501886174163, 'bagging_freq': 4, 'lambda_l1': 0.0068548535602029935, 'lambda_l2': 0.0019571597209700254, 'learning_rate': 0.25217980695049225, 'max_depth': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5727527857427196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5727527857427196\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2073366088785194e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2073366088785194e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.586558226753304e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.586558226753304e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7713845502468794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713845502468794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5727527857427196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5727527857427196\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2073366088785194e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2073366088785194e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.586558226753304e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.586558226753304e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7713845502468794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713845502468794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5727527857427196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5727527857427196\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2073366088785194e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2073366088785194e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.586558226753304e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.586558226753304e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7713845502468794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713845502468794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5727527857427196, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5727527857427196\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.2073366088785194e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2073366088785194e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.586558226753304e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.586558226753304e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7713845502468794, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713845502468794\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7398806064642335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398806064642335\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0068548535602029935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0068548535602029935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0019571597209700254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0019571597209700254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6609501886174163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6609501886174163\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7398806064642335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398806064642335\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0068548535602029935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0068548535602029935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0019571597209700254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0019571597209700254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6609501886174163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6609501886174163\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7398806064642335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398806064642335\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0068548535602029935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0068548535602029935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0019571597209700254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0019571597209700254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6609501886174163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6609501886174163\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7398806064642335, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7398806064642335\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0068548535602029935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0068548535602029935\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0019571597209700254, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0019571597209700254\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6609501886174163, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6609501886174163\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,057] Trial 27 finished with value: 0.0 and parameters: {'num_leaves': 55, 'min_data_in_leaf': 98, 'feature_fraction': 0.6825593909864852, 'bagging_fraction': 0.9332595350756139, 'bagging_freq': 2, 'lambda_l1': 0.9688311768265608, 'lambda_l2': 0.028994832525363074, 'learning_rate': 0.1560070567946536, 'max_depth': 4}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,166] Trial 28 finished with value: 0.0 and parameters: {'num_leaves': 20, 'min_data_in_leaf': 38, 'feature_fraction': 0.7885735553913649, 'bagging_fraction': 0.8560505393111757, 'bagging_freq': 6, 'lambda_l1': 0.00016490785831187277, 'lambda_l2': 0.00027481679856288486, 'learning_rate': 0.2123412170412334, 'max_depth': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825593909864852, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825593909864852\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9688311768265608, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9688311768265608\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.028994832525363074, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028994832525363074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9332595350756139, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9332595350756139\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825593909864852, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825593909864852\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9688311768265608, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9688311768265608\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.028994832525363074, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028994832525363074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9332595350756139, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9332595350756139\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825593909864852, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825593909864852\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9688311768265608, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9688311768265608\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.028994832525363074, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028994832525363074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9332595350756139, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9332595350756139\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=98, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=98\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6825593909864852, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6825593909864852\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9688311768265608, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9688311768265608\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.028994832525363074, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.028994832525363074\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9332595350756139, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9332595350756139\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7885735553913649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7885735553913649\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016490785831187277, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016490785831187277\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00027481679856288486, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00027481679856288486\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8560505393111757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560505393111757\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7885735553913649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7885735553913649\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016490785831187277, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016490785831187277\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00027481679856288486, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00027481679856288486\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8560505393111757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560505393111757\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7885735553913649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7885735553913649\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016490785831187277, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016490785831187277\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00027481679856288486, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00027481679856288486\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8560505393111757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560505393111757\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7885735553913649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7885735553913649\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016490785831187277, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016490785831187277\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00027481679856288486, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00027481679856288486\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8560505393111757, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8560505393111757\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,270] Trial 29 finished with value: 0.0 and parameters: {'num_leaves': 119, 'min_data_in_leaf': 70, 'feature_fraction': 0.7590827220078642, 'bagging_fraction': 0.8017303069966705, 'bagging_freq': 7, 'lambda_l1': 1.9858388233664705e-06, 'lambda_l2': 3.250011050984608e-05, 'learning_rate': 0.2880590820439817, 'max_depth': 8}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,379] Trial 30 finished with value: 0.0 and parameters: {'num_leaves': 105, 'min_data_in_leaf': 16, 'feature_fraction': 0.4524478930557919, 'bagging_fraction': 0.739061389319719, 'bagging_freq': 3, 'lambda_l1': 0.08423329809372505, 'lambda_l2': 9.919269857338322e-05, 'learning_rate': 0.0473825042974877, 'max_depth': 7}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7590827220078642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7590827220078642\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9858388233664705e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9858388233664705e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.250011050984608e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.250011050984608e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8017303069966705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8017303069966705\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7590827220078642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7590827220078642\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9858388233664705e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9858388233664705e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.250011050984608e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.250011050984608e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8017303069966705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8017303069966705\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7590827220078642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7590827220078642\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9858388233664705e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9858388233664705e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.250011050984608e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.250011050984608e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8017303069966705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8017303069966705\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=70, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=70\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7590827220078642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7590827220078642\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9858388233664705e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9858388233664705e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.250011050984608e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.250011050984608e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8017303069966705, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8017303069966705\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4524478930557919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4524478930557919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08423329809372505, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08423329809372505\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.919269857338322e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.919269857338322e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.739061389319719, subsample=1.0 will be ignored. Current value: bagging_fraction=0.739061389319719\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4524478930557919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4524478930557919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08423329809372505, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08423329809372505\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.919269857338322e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.919269857338322e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.739061389319719, subsample=1.0 will be ignored. Current value: bagging_fraction=0.739061389319719\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4524478930557919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4524478930557919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08423329809372505, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08423329809372505\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.919269857338322e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.919269857338322e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.739061389319719, subsample=1.0 will be ignored. Current value: bagging_fraction=0.739061389319719\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4524478930557919, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4524478930557919\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08423329809372505, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08423329809372505\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.919269857338322e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.919269857338322e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.739061389319719, subsample=1.0 will be ignored. Current value: bagging_fraction=0.739061389319719\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,498] Trial 31 finished with value: 0.0 and parameters: {'num_leaves': 161, 'min_data_in_leaf': 80, 'feature_fraction': 0.8227835544616504, 'bagging_fraction': 0.7281515111027536, 'bagging_freq': 1, 'lambda_l1': 4.558795092724176e-06, 'lambda_l2': 1.099915202393984e-07, 'learning_rate': 0.2317799842306553, 'max_depth': 11}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,597] Trial 32 finished with value: 0.0 and parameters: {'num_leaves': 127, 'min_data_in_leaf': 65, 'feature_fraction': 0.7648023743048107, 'bagging_fraction': 0.8235737814938202, 'bagging_freq': 2, 'lambda_l1': 9.604326116775108e-06, 'lambda_l2': 0.0007121380265184028, 'learning_rate': 0.29997968850209333, 'max_depth': 8}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8227835544616504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8227835544616504\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.558795092724176e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.558795092724176e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.099915202393984e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.099915202393984e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7281515111027536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7281515111027536\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8227835544616504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8227835544616504\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.558795092724176e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.558795092724176e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.099915202393984e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.099915202393984e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7281515111027536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7281515111027536\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8227835544616504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8227835544616504\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.558795092724176e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.558795092724176e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.099915202393984e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.099915202393984e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7281515111027536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7281515111027536\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=80, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8227835544616504, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8227835544616504\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.558795092724176e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.558795092724176e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.099915202393984e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.099915202393984e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7281515111027536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7281515111027536\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7648023743048107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7648023743048107\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.604326116775108e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.604326116775108e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0007121380265184028, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007121380265184028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8235737814938202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8235737814938202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7648023743048107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7648023743048107\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.604326116775108e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.604326116775108e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0007121380265184028, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007121380265184028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8235737814938202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8235737814938202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7648023743048107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7648023743048107\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.604326116775108e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.604326116775108e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0007121380265184028, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007121380265184028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8235737814938202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8235737814938202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7648023743048107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7648023743048107\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.604326116775108e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.604326116775108e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0007121380265184028, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007121380265184028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8235737814938202, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8235737814938202\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,716] Trial 33 finished with value: 0.0 and parameters: {'num_leaves': 185, 'min_data_in_leaf': 31, 'feature_fraction': 0.7090817615003873, 'bagging_fraction': 0.7878442168915021, 'bagging_freq': 4, 'lambda_l1': 3.8283137611368586e-07, 'lambda_l2': 1.6598986831940508e-06, 'learning_rate': 0.18758995649242885, 'max_depth': 6}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,855] Trial 34 finished with value: 0.0 and parameters: {'num_leaves': 80, 'min_data_in_leaf': 79, 'feature_fraction': 0.9577234659835758, 'bagging_fraction': 0.6688445727400291, 'bagging_freq': 1, 'lambda_l1': 0.009366084776280724, 'lambda_l2': 0.005636309096271591, 'learning_rate': 0.11693032719269374, 'max_depth': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7090817615003873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7090817615003873\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8283137611368586e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8283137611368586e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6598986831940508e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6598986831940508e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7878442168915021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7878442168915021\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7090817615003873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7090817615003873\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8283137611368586e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8283137611368586e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6598986831940508e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6598986831940508e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7878442168915021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7878442168915021\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7090817615003873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7090817615003873\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8283137611368586e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8283137611368586e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6598986831940508e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6598986831940508e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7878442168915021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7878442168915021\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=31, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=31\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7090817615003873, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7090817615003873\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.8283137611368586e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.8283137611368586e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6598986831940508e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6598986831940508e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7878442168915021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7878442168915021\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=79, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=79\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9577234659835758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9577234659835758\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009366084776280724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009366084776280724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005636309096271591, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005636309096271591\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6688445727400291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6688445727400291\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=79, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=79\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9577234659835758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9577234659835758\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009366084776280724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009366084776280724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005636309096271591, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005636309096271591\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6688445727400291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6688445727400291\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=79, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=79\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9577234659835758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9577234659835758\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009366084776280724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009366084776280724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005636309096271591, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005636309096271591\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6688445727400291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6688445727400291\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=79, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=79\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9577234659835758, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9577234659835758\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.009366084776280724, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.009366084776280724\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.005636309096271591, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005636309096271591\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6688445727400291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6688445727400291\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:39,947] Trial 35 finished with value: 0.0 and parameters: {'num_leaves': 100, 'min_data_in_leaf': 87, 'feature_fraction': 0.9062013551023949, 'bagging_fraction': 0.7389003628875472, 'bagging_freq': 3, 'lambda_l1': 1.0340770591991642e-08, 'lambda_l2': 8.958603947236172e-06, 'learning_rate': 0.15425753753601054, 'max_depth': 3}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9062013551023949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9062013551023949\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0340770591991642e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0340770591991642e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.958603947236172e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.958603947236172e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7389003628875472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7389003628875472\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9062013551023949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9062013551023949\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0340770591991642e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0340770591991642e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.958603947236172e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.958603947236172e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7389003628875472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7389003628875472\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9062013551023949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9062013551023949\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0340770591991642e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0340770591991642e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.958603947236172e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.958603947236172e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7389003628875472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7389003628875472\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=87, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=87\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9062013551023949, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9062013551023949\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0340770591991642e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0340770591991642e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.958603947236172e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.958603947236172e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7389003628875472, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7389003628875472\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5343487114190562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5343487114190562\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.641138540322174e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.641138540322174e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.900419153028218e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.900419153028218e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.916873325725909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.916873325725909\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5343487114190562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5343487114190562\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.641138540322174e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.641138540322174e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.900419153028218e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.900419153028218e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.916873325725909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.916873325725909\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5343487114190562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5343487114190562\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.641138540322174e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.641138540322174e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.900419153028218e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.900419153028218e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.916873325725909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.916873325725909\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:40,150] Trial 36 finished with value: 0.014000000000000012 and parameters: {'num_leaves': 135, 'min_data_in_leaf': 18, 'feature_fraction': 0.5343487114190562, 'bagging_fraction': 0.916873325725909, 'bagging_freq': 4, 'lambda_l1': 7.641138540322174e-08, 'lambda_l2': 5.900419153028218e-05, 'learning_rate': 0.012533265457089177, 'max_depth': 11}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:40,251] Trial 37 finished with value: 0.0 and parameters: {'num_leaves': 148, 'min_data_in_leaf': 56, 'feature_fraction': 0.675219222943598, 'bagging_fraction': 0.8770431432200602, 'bagging_freq': 1, 'lambda_l1': 2.7487162488256157e-05, 'lambda_l2': 8.680824012125455e-06, 'learning_rate': 0.10065355647106343, 'max_depth': 4}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's binary_error: 0.014\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5343487114190562, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5343487114190562\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.641138540322174e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.641138540322174e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.900419153028218e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.900419153028218e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.916873325725909, subsample=1.0 will be ignored. Current value: bagging_fraction=0.916873325725909\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] feature_fraction is set=0.675219222943598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.675219222943598\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7487162488256157e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7487162488256157e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.680824012125455e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.680824012125455e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8770431432200602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770431432200602\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] feature_fraction is set=0.675219222943598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.675219222943598\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7487162488256157e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7487162488256157e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.680824012125455e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.680824012125455e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8770431432200602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770431432200602\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] feature_fraction is set=0.675219222943598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.675219222943598\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7487162488256157e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7487162488256157e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.680824012125455e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.680824012125455e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8770431432200602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770431432200602\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=56, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=56\n",
      "[LightGBM] [Warning] feature_fraction is set=0.675219222943598, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.675219222943598\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7487162488256157e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7487162488256157e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.680824012125455e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.680824012125455e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8770431432200602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8770431432200602\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:40,363] Trial 38 finished with value: 0.0 and parameters: {'num_leaves': 121, 'min_data_in_leaf': 27, 'feature_fraction': 0.7314167232967127, 'bagging_fraction': 0.8369372873163463, 'bagging_freq': 2, 'lambda_l1': 0.00018167102256519193, 'lambda_l2': 2.142432432692513e-08, 'learning_rate': 0.0820586217550112, 'max_depth': 6}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:40,481] Trial 39 finished with value: 0.0 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 65, 'feature_fraction': 0.9961408408996473, 'bagging_fraction': 0.5530973093860266, 'bagging_freq': 6, 'lambda_l1': 0.024556743519180656, 'lambda_l2': 2.9056180527443975e-07, 'learning_rate': 0.016691862082099076, 'max_depth': 10}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7314167232967127, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7314167232967127\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018167102256519193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018167102256519193\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.142432432692513e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.142432432692513e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8369372873163463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8369372873163463\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7314167232967127, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7314167232967127\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018167102256519193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018167102256519193\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.142432432692513e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.142432432692513e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8369372873163463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8369372873163463\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7314167232967127, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7314167232967127\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018167102256519193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018167102256519193\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.142432432692513e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.142432432692513e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8369372873163463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8369372873163463\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7314167232967127, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7314167232967127\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00018167102256519193, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00018167102256519193\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.142432432692513e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.142432432692513e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8369372873163463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8369372873163463\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9961408408996473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9961408408996473\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.024556743519180656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.024556743519180656\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.9056180527443975e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9056180527443975e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5530973093860266, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5530973093860266\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9961408408996473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9961408408996473\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.024556743519180656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.024556743519180656\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.9056180527443975e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9056180527443975e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5530973093860266, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5530973093860266\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9961408408996473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9961408408996473\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.024556743519180656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.024556743519180656\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.9056180527443975e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9056180527443975e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5530973093860266, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5530973093860266\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9961408408996473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9961408408996473\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.024556743519180656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.024556743519180656\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.9056180527443975e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.9056180527443975e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5530973093860266, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5530973093860266\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:40,692] Trial 40 finished with value: 0.0 and parameters: {'num_leaves': 86, 'min_data_in_leaf': 47, 'feature_fraction': 0.8646736194073155, 'bagging_fraction': 0.7140261858749922, 'bagging_freq': 7, 'lambda_l1': 6.900178148600518e-07, 'lambda_l2': 1.6426945921585949e-06, 'learning_rate': 0.0497574481166744, 'max_depth': 15}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8646736194073155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8646736194073155\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.900178148600518e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.900178148600518e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6426945921585949e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6426945921585949e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7140261858749922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7140261858749922\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8646736194073155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8646736194073155\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.900178148600518e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.900178148600518e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6426945921585949e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6426945921585949e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7140261858749922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7140261858749922\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8646736194073155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8646736194073155\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.900178148600518e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.900178148600518e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6426945921585949e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6426945921585949e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7140261858749922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7140261858749922\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8646736194073155, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8646736194073155\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.900178148600518e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.900178148600518e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6426945921585949e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6426945921585949e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7140261858749922, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7140261858749922\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:40,831] Trial 41 finished with value: 0.0 and parameters: {'num_leaves': 170, 'min_data_in_leaf': 33, 'feature_fraction': 0.9531379964747101, 'bagging_fraction': 0.7625331211099855, 'bagging_freq': 1, 'lambda_l1': 1.5147473689685913e-05, 'lambda_l2': 9.320899602934008e-08, 'learning_rate': 0.04219426953292198, 'max_depth': 10}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9531379964747101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9531379964747101\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5147473689685913e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5147473689685913e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.320899602934008e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.320899602934008e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7625331211099855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7625331211099855\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9531379964747101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9531379964747101\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5147473689685913e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5147473689685913e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.320899602934008e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.320899602934008e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7625331211099855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7625331211099855\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9531379964747101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9531379964747101\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5147473689685913e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5147473689685913e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.320899602934008e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.320899602934008e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7625331211099855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7625331211099855\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=33, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=33\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9531379964747101, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9531379964747101\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5147473689685913e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5147473689685913e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.320899602934008e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.320899602934008e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7625331211099855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7625331211099855\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8918097093734467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8918097093734467\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.489872606405372e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.489872606405372e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2147987631790682e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2147987631790682e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.671062928714021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.671062928714021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8918097093734467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8918097093734467\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.489872606405372e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.489872606405372e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2147987631790682e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2147987631790682e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.671062928714021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.671062928714021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8918097093734467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8918097093734467\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.489872606405372e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.489872606405372e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2147987631790682e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2147987631790682e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.671062928714021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.671062928714021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's binary_error: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:40,981] Trial 42 finished with value: 0.0 and parameters: {'num_leaves': 141, 'min_data_in_leaf': 22, 'feature_fraction': 0.8918097093734467, 'bagging_fraction': 0.671062928714021, 'bagging_freq': 1, 'lambda_l1': 3.489872606405372e-06, 'lambda_l2': 1.2147987631790682e-08, 'learning_rate': 0.055191287404345896, 'max_depth': 12}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:41,132] Trial 43 finished with value: 0.0 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 39, 'feature_fraction': 0.9733963332770477, 'bagging_fraction': 0.8620082768405904, 'bagging_freq': 3, 'lambda_l1': 7.381330884755061e-05, 'lambda_l2': 2.2712188020698828e-07, 'learning_rate': 0.028890263376533297, 'max_depth': 14}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8918097093734467, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8918097093734467\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.489872606405372e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.489872606405372e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2147987631790682e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2147987631790682e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.671062928714021, subsample=1.0 will be ignored. Current value: bagging_fraction=0.671062928714021\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9733963332770477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9733963332770477\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.381330884755061e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.381330884755061e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2712188020698828e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2712188020698828e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8620082768405904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8620082768405904\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9733963332770477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9733963332770477\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.381330884755061e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.381330884755061e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2712188020698828e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2712188020698828e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8620082768405904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8620082768405904\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9733963332770477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9733963332770477\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.381330884755061e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.381330884755061e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2712188020698828e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2712188020698828e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8620082768405904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8620082768405904\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=39, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=39\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9733963332770477, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9733963332770477\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.381330884755061e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.381330884755061e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2712188020698828e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2712188020698828e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8620082768405904, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8620082768405904\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:41,258] Trial 44 finished with value: 0.0 and parameters: {'num_leaves': 129, 'min_data_in_leaf': 58, 'feature_fraction': 0.7808085125099244, 'bagging_fraction': 0.788880263326723, 'bagging_freq': 2, 'lambda_l1': 0.002110646473018375, 'lambda_l2': 4.8140099035445247e-08, 'learning_rate': 0.06953235760991643, 'max_depth': 3}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:41,380] Trial 45 finished with value: 0.0 and parameters: {'num_leaves': 189, 'min_data_in_leaf': 19, 'feature_fraction': 0.8346950854883446, 'bagging_fraction': 0.7070008408224819, 'bagging_freq': 1, 'lambda_l1': 1.5413318080928973, 'lambda_l2': 8.044745873429431e-07, 'learning_rate': 0.12807925860481056, 'max_depth': 9}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7808085125099244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7808085125099244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002110646473018375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002110646473018375\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.8140099035445247e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.8140099035445247e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.788880263326723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.788880263326723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7808085125099244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7808085125099244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002110646473018375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002110646473018375\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.8140099035445247e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.8140099035445247e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.788880263326723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.788880263326723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7808085125099244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7808085125099244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002110646473018375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002110646473018375\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.8140099035445247e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.8140099035445247e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.788880263326723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.788880263326723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=58, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=58\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7808085125099244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7808085125099244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002110646473018375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002110646473018375\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.8140099035445247e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.8140099035445247e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.788880263326723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.788880263326723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8346950854883446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8346950854883446\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5413318080928973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5413318080928973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.044745873429431e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.044745873429431e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7070008408224819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7070008408224819\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8346950854883446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8346950854883446\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5413318080928973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5413318080928973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.044745873429431e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.044745873429431e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7070008408224819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7070008408224819\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8346950854883446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8346950854883446\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5413318080928973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5413318080928973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.044745873429431e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.044745873429431e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7070008408224819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7070008408224819\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8346950854883446, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8346950854883446\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5413318080928973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5413318080928973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.044745873429431e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.044745873429431e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7070008408224819, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7070008408224819\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:41,503] Trial 46 finished with value: 0.0 and parameters: {'num_leaves': 165, 'min_data_in_leaf': 10, 'feature_fraction': 0.929301455124896, 'bagging_fraction': 0.9536308032040914, 'bagging_freq': 5, 'lambda_l1': 1.0212834903070396e-07, 'lambda_l2': 0.0001189044829791971, 'learning_rate': 0.03470183878241205, 'max_depth': 5}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.929301455124896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.929301455124896\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0212834903070396e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0212834903070396e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001189044829791971, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001189044829791971\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9536308032040914, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9536308032040914\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.929301455124896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.929301455124896\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0212834903070396e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0212834903070396e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001189044829791971, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001189044829791971\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9536308032040914, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9536308032040914\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.929301455124896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.929301455124896\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0212834903070396e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0212834903070396e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001189044829791971, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001189044829791971\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9536308032040914, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9536308032040914\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.929301455124896, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.929301455124896\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0212834903070396e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0212834903070396e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001189044829791971, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001189044829791971\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9536308032040914, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9536308032040914\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8921657720890301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8921657720890301\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5205509641661984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5205509641661984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0005059269954085174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005059269954085174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8954714181542782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8954714181542782\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8921657720890301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8921657720890301\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5205509641661984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5205509641661984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0005059269954085174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005059269954085174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8954714181542782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8954714181542782\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8921657720890301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8921657720890301\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5205509641661984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5205509641661984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0005059269954085174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005059269954085174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8954714181542782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8954714181542782\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[54]\tvalid_0's binary_error: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:41,671] Trial 47 finished with value: 0.0 and parameters: {'num_leaves': 41, 'min_data_in_leaf': 35, 'feature_fraction': 0.8921657720890301, 'bagging_fraction': 0.8954714181542782, 'bagging_freq': 2, 'lambda_l1': 0.5205509641661984, 'lambda_l2': 0.0005059269954085174, 'learning_rate': 0.010131112810476132, 'max_depth': 11}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:41,788] Trial 48 finished with value: 0.0 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 42, 'feature_fraction': 0.46531652022213443, 'bagging_fraction': 0.7492086468035789, 'bagging_freq': 7, 'lambda_l1': 7.979828373487624, 'lambda_l2': 1.637101781235738, 'learning_rate': 0.02155037735545697, 'max_depth': 4}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\91983\\AppData\\Local\\Temp\\ipykernel_12352\\1811967142.py:88: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8921657720890301, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8921657720890301\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5205509641661984, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5205509641661984\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0005059269954085174, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005059269954085174\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8954714181542782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8954714181542782\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46531652022213443, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46531652022213443\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.979828373487624, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.979828373487624\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.637101781235738, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.637101781235738\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7492086468035789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7492086468035789\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46531652022213443, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46531652022213443\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.979828373487624, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.979828373487624\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.637101781235738, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.637101781235738\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7492086468035789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7492086468035789\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46531652022213443, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46531652022213443\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.979828373487624, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.979828373487624\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.637101781235738, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.637101781235738\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7492086468035789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7492086468035789\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.46531652022213443, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.46531652022213443\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.979828373487624, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.979828373487624\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.637101781235738, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.637101781235738\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7492086468035789, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7492086468035789\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-29 22:11:41,930] Trial 49 finished with value: 0.0 and parameters: {'num_leaves': 195, 'min_data_in_leaf': 27, 'feature_fraction': 0.6207075163844648, 'bagging_fraction': 0.5727182555658987, 'bagging_freq': 4, 'lambda_l1': 0.1690912034629656, 'lambda_l2': 3.1741312505690913e-06, 'learning_rate': 0.24541812405035962, 'max_depth': 10}. Best is trial 0 with value: 0.0.\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6207075163844648, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6207075163844648\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1690912034629656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1690912034629656\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1741312505690913e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1741312505690913e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5727182555658987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5727182555658987\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6207075163844648, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6207075163844648\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1690912034629656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1690912034629656\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1741312505690913e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1741312505690913e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5727182555658987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5727182555658987\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 1620, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2000, number of used features: 12\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6207075163844648, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6207075163844648\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1690912034629656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1690912034629656\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1741312505690913e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1741312505690913e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5727182555658987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5727182555658987\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.810000 -> initscore=1.450010\n",
      "[LightGBM] [Info] Start training from score 1.450010\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's binary_error: 0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6207075163844648, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6207075163844648\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1690912034629656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1690912034629656\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1741312505690913e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1741312505690913e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5727182555658987, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5727182555658987\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's binary_error: 0\n",
      "✅ LightGBM Model Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Stacking Model Accuracy: 1.0000\n",
      "🌟 LightGBM Model Accuracy: 1.0000\n",
      "🎉 Models and scaler saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "\n",
    "# ---- 🔹 KNN Imputation Function ----\n",
    "def KNN_Imputer(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        temp_df = df.copy()\n",
    "        for x in df.columns:\n",
    "            if x == col:\n",
    "                continue\n",
    "            temp_df[x].fillna(value=temp_df[x].mean(), inplace=True)\n",
    "\n",
    "        other_cols = [x for x in df.columns if x != col]\n",
    "        X = temp_df[other_cols][df[col].notna()]\n",
    "        y = temp_df[col][df[col].notna()]\n",
    "\n",
    "        neigh = KNeighborsRegressor(n_neighbors=3)\n",
    "        neigh.fit(np.array(X), np.array(y))\n",
    "\n",
    "        print(f\"🔹 Imputing {col}\")\n",
    "        df.loc[df[col].isnull(), col] = neigh.predict(temp_df[other_cols][df[col].isnull()])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ---- 🔹 Load Dataset ----\n",
    "df = pd.read_csv(r\"loan.csv\")\n",
    "\n",
    "# Drop Loan_ID\n",
    "df.drop(columns=[\"Loan_ID\"], inplace=True)\n",
    "\n",
    "# Convert categorical variables\n",
    "df[\"Gender\"] = df[\"Gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "df[\"Married\"] = df[\"Married\"].map({\"Yes\": 1, \"No\": 0})\n",
    "df[\"Education\"] = df[\"Education\"].map({\"Graduate\": 1, \"Not Graduate\": 0})\n",
    "df[\"Self_Employed\"] = df[\"Self_Employed\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Handle \"Dependents\" column (convert \"3+\" to integer 3)\n",
    "df[\"Dependents\"] = df[\"Dependents\"].replace(\"3+\", 3).astype(float)\n",
    "\n",
    "# One-hot encode \"Property_Area\"\n",
    "df = pd.get_dummies(df, columns=[\"Property_Area\"], drop_first=True)\n",
    "\n",
    "# Convert \"Loan_Status\" to binary (Y=1, N=0)\n",
    "df[\"Loan_Status\"] = df[\"Loan_Status\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "# Apply KNN Imputation\n",
    "df = KNN_Imputer(df)\n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "X = df.drop(columns=[\"Loan_Status\"])\n",
    "y = df[\"Loan_Status\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# ---- 🔹 OPTUNA HYPERPARAMETER TUNING ----\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_error\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 200),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 100),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params, random_state=42)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        callbacks=[lgb.early_stopping(50)]\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    return 1 - accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Run Optuna to find the best hyperparameters\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_error\",\n",
    "    \"verbosity\": -1,  # ✅ Use this instead of verbose\n",
    "    \"boosting_type\": \"gbdt\"\n",
    "})\n",
    "\n",
    "# ---- 🔹 TRAIN FINAL LIGHTGBM MODEL ----\n",
    "lgb_model = lgb.LGBMClassifier(**best_params, random_state=42)\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    callbacks=[lgb.early_stopping(50)]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "lgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ LightGBM Model Accuracy: {lgb_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# ---- 🔹 STACKING CLASSIFIER ----\n",
    "estimators = [\n",
    "    (\"lgb\", lgb.LGBMClassifier(**best_params)),\n",
    "    (\"rf\", RandomForestClassifier(max_depth=32, random_state=1)),\n",
    "]\n",
    "\n",
    "stacker = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier(), cv=5)\n",
    "stacker.fit(X_train, y_train)\n",
    "\n",
    "# Stacking Predictions\n",
    "stacker_pred = stacker.predict(X_test)\n",
    "stacker_accuracy = accuracy_score(y_test, stacker_pred)\n",
    "\n",
    "print(f\"🚀 Stacking Model Accuracy: {stacker_accuracy:.4f}\")\n",
    "print(f\"🌟 LightGBM Model Accuracy: {lgb_accuracy:.4f}\")\n",
    "\n",
    "# Save models\n",
    "joblib.dump(lgb_model, \"LightGBM_Optimized.model\")\n",
    "joblib.dump(stacker, \"Stacking_Optimized.model\")\n",
    "joblib.dump(scaler, \"Scaler.model\")\n",
    "\n",
    "print(\"🎉 Models and scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING VOTING CLASSIFIER (ENSEMBLE MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:38:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.9995\n",
      "Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\91983\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ensemble.model']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load all trained models\n",
    "models = {\n",
    "    \"KNN\": joblib.load(\"KNN_Classifier_Optimized2.model\"),\n",
    "    \"Decision Tree\": joblib.load(\"Decison_Tree_Classifier.model\"),\n",
    "    \"Random Forest\": joblib.load(\"RandomForest_Classifier.model\"),\n",
    "    \"CATBoost\": joblib.load(\"CatBoost_Classifier.model\"),\n",
    "    \"LightGBM\": joblib.load(\"LightGBM_Optimized.model\"),\n",
    "    \"XGBoost\": joblib.load(\"best_xgb_loan_model.h5\"),\n",
    "}\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"loan.csv\")\n",
    "\n",
    "# Handling missing values\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Encoding categorical variables\n",
    "categorical_cols = ['Gender', 'Dependents', 'Married', 'Education', 'Self_Employed', 'Credit_History']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "df['Loan_Status'] = df['Loan_Status'].astype('category').cat.codes\n",
    "\n",
    "# One-hot encoding for Property_Area\n",
    "dummy_data = pd.get_dummies(df['Property_Area'])\n",
    "df = pd.concat([df, dummy_data], axis=1)\n",
    "df.drop(['Property_Area'], axis=1, inplace=True)\n",
    "\n",
    "# Drop Loan_ID column\n",
    "df.drop(['Loan_ID'], axis=1, inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=['Loan_Status'])\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"knn\", models[\"KNN\"]),\n",
    "        (\"dt\", models[\"Decision Tree\"]),\n",
    "        (\"rf\", models[\"Random Forest\"]),\n",
    "        (\"xgb\", models[\"XGBoost\"]),\n",
    "        (\"cat\", models[\"CATBoost\"]),\n",
    "        (\"lgbm\", models[\"LightGBM\"])\n",
    "    ],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "\n",
    "# Train ensemble model\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "cv_scores = cross_val_score(voting_clf, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(f\"Cross-validation accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Test accuracy\n",
    "test_score = voting_clf.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_score:.4f}\")\n",
    "\n",
    "# Save the ensemble model\n",
    "joblib.dump(voting_clf, \"Ensemble.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
